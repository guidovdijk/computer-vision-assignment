{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 72 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "from numpy import expand_dims\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "TEST_TUBE_PATH = 'C:\\\\Users\\\\vangu\\\\OneDrive - Hogeschool Inholland\\\\Year 3\\\\Big Data and AI\\\\Computer Vision\\\\Assignment_1\\\\Test Tubes\\\\'\n",
    "BATCH_SIZE = 6\n",
    "input_shape = 300\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=(0.2, 0.5),\n",
    "    rotation_range=90,\n",
    "    validation_split=0.2,\n",
    "    # samplewise_std_normalization=True,\n",
    ")\n",
    "# valgen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     validation_split=0.2,\n",
    "# )\n",
    "\n",
    "# train_gen = datagen.flow_from_directory(\n",
    "#         TEST_TUBE_PATH, \n",
    "#         target_size=(input_shape, input_shape), \n",
    "#         classes = ['BD-Vacutainer','EDTA(K2)','Monovette','PLAIN','SGS', 'Vacuette', 'Vacutest', 'Venosafe'],\n",
    "#         class_mode='categorical',\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#         subset='training'\n",
    "# )\n",
    "\n",
    "test = datagen.flow_from_directory(\n",
    "    TEST_TUBE_PATH, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    save_to_dir=TEST_TUBE_PATH,\n",
    "    save_prefix='aug_',\n",
    "    target_size=(input_shape, input_shape), \n",
    ")\n",
    "\n",
    "# for x in range(10):\n",
    "#     print(test)\n",
    "#     test.next()\n",
    "\n",
    "# validation_gen = valgen.flow_from_directory(\n",
    "#         TEST_TUBE_PATH, \n",
    "#         target_size=(input_shape, input_shape), \n",
    "#         classes = ['BD-Vacutainer','EDTA(K2)','Monovette','PLAIN','SGS', 'Vacuette', 'Vacutest', 'Venosafe'],\n",
    "#         class_mode='categorical',\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#         subset='validation'\n",
    "# )\n",
    "\n",
    "\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n",
    "#     # The first convolution\n",
    "#     tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(input_shape, input_shape, 3)),\n",
    "#     tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#         # The second convolution\n",
    "#     tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(2,2),\n",
    "#     # The third convolution\n",
    "#     tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(2,2),\n",
    "#     # The fourth convolution\n",
    "#     tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(2,2),\n",
    "#     # The fifth convolution\n",
    "#     tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(2,2),\n",
    "#     # Flatten the results to feed into a dense layer\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     # 128 neuron in the fully-connected layer\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     # 5 output neurons for 5 classes with the softmax activation\n",
    "#     tf.keras.layers.Dense(8, activation='softmax')\n",
    "# ])\n",
    "\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# training_steps = train_gen.samples // BATCH_SIZE\n",
    "# testing_steps = validation_gen.samples // BATCH_SIZE\n",
    "\n",
    "# print(training_steps,testing_steps)\n",
    "# history = model.fit(\n",
    "#     train_gen, \n",
    "#     validation_data=validation_gen,\n",
    "#     epochs = 50,\n",
    "#     steps_per_epoch = training_steps,\n",
    "#     validation_steps = testing_steps,\n",
    "# )\n",
    "\n",
    "# _, accuracy = model.evaluate(validation_gen)\n",
    "# print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "# # model = Sequential()\n",
    "# # # model.add(Flatten())\n",
    "# # model.add(Dense(12, activation='relu'))\n",
    "# # model.add(Dense(32, activation='relu'))\n",
    "# # model.add(Dense(32, activation='relu'))\n",
    "# # model.add(Dense(16, activation='relu'))\n",
    "# # model.add(Dense(2, activation='sigmoid'))\n",
    "# # model.build(input_shape)\n",
    "# model.summary()\n",
    "# model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'], run_eagerly=True)\n",
    "\n",
    "# model.fit(\n",
    "#     train_gen,\n",
    "#     validation_data=validation_gen,\n",
    "#     epochs=25,\n",
    "#     steps_per_epoch=train_gen.samples // BATCH_SIZE,\n",
    "#     validation_steps=validation_gen.samples // BATCH_SIZE\n",
    "# )\n",
    "\n",
    "# _, accuracy = model.evaluate(train_gen, validation_gen)\n",
    "# print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "\n",
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs = range(len(acc))\n",
    "\n",
    "# plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "# plt.title('Training and validation accuracy')\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "# plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 62 images belonging to 8 classes.\n",
      "Found 10 images belonging to 8 classes.\n",
      "62 10\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 300, 300, 32)      832       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 300, 300, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 150, 150, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 150, 150, 64)      51264     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 150, 150, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 75, 75, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 75, 75, 90)        144090    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 75, 75, 90)       360       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 37, 37, 90)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 123210)            0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1024)              126168064 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,373,194\n",
      "Trainable params: 126,372,822\n",
      "Non-trainable params: 372\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_2/conv2d_6/Relu' defined at (most recent call last):\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\vangu\\AppData\\Local\\Temp/ipykernel_18028/3249264740.py\", line 92, in <module>\n      model.fit(train_gen,\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 275, in call\n      return self.activation(outputs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\activations.py\", line 311, in relu\n      return backend.relu(x, alpha=alpha, max_value=max_value, threshold=threshold)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 4956, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_2/conv2d_6/Relu'\nFused conv implementation does not support grouped convolutions for now.\n\t [[{{node sequential_2/conv2d_6/Relu}}]] [Op:__inference_train_function_11667]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18028/3249264740.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m model.fit(train_gen,\n\u001b[0m\u001b[0;32m     93\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vangu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_2/conv2d_6/Relu' defined at (most recent call last):\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\vangu\\AppData\\Local\\Temp/ipykernel_18028/3249264740.py\", line 92, in <module>\n      model.fit(train_gen,\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 275, in call\n      return self.activation(outputs)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\activations.py\", line 311, in relu\n      return backend.relu(x, alpha=alpha, max_value=max_value, threshold=threshold)\n    File \"c:\\Users\\vangu\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 4956, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential_2/conv2d_6/Relu'\nFused conv implementation does not support grouped convolutions for now.\n\t [[{{node sequential_2/conv2d_6/Relu}}]] [Op:__inference_train_function_11667]"
     ]
    }
   ],
   "source": [
    "from numpy import expand_dims\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "TEST_TUBE_PATH = r'./Test Tubes/'\n",
    "BATCH_SIZE = 1\n",
    "input_shape = 300\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # horizontal_flip=True,\n",
    "    # vertical_flip=True,\n",
    "    brightness_range=(0.2, 0.5),\n",
    "    rotation_range=90,\n",
    "    validation_split=0.2,\n",
    "    # samplewise_std_normalization=True,\n",
    ")\n",
    "valgen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "        # classes = ['BD-Vacutainer','EDTA(K2)','Monovette','PLAIN','SGS', 'Vacuette', 'Vacutest', 'Venosafe'],\n",
    "train_gen = datagen.flow_from_directory(\n",
    "        TEST_TUBE_PATH, \n",
    "        target_size=(input_shape, input_shape),\n",
    "        class_mode='categorical',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        subset='training'\n",
    ")\n",
    "\n",
    "\n",
    "validation_gen = valgen.flow_from_directory(\n",
    "        TEST_TUBE_PATH, \n",
    "        target_size=(input_shape, input_shape), \n",
    "        class_mode='categorical',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([    \n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=5, padding='same', activation='relu', input_shape=(input_shape, input_shape, 1)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=5, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(2),\n",
    "  \n",
    "    tf.keras.layers.Conv2D(filters=90, kernel_size=5, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool2D(2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(units=1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.35),\n",
    "    Dense(units=8, activation='softmax'),\n",
    "])\n",
    "\n",
    "print(train_gen.samples, validation_gen.samples)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adagrad',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_steps = train_gen.samples // BATCH_SIZE\n",
    "testing_steps = validation_gen.samples // BATCH_SIZE\n",
    "\n",
    "# print(training_steps,testing_steps)\n",
    "# model.fit(\n",
    "#     train_gen, \n",
    "#     validation_data=validation_gen,\n",
    "#     epochs = 50,\n",
    "#     steps_per_epoch = training_steps,\n",
    "#     validation_steps = testing_steps,\n",
    "# )\n",
    "\n",
    "\n",
    "model.fit(train_gen,\n",
    "                    steps_per_epoch=train_gen.samples  // BATCH_SIZE,\n",
    "                    epochs=40,\n",
    "                    validation_data=validation_gen,\n",
    "                    validation_steps = validation_gen.samples // BATCH_SIZE)\n",
    "# _, accuracy = model.evaluate(validation_gen)\n",
    "# print('Accuracy: %.2f' % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # model = Sequential()\n",
    "# # # model.add(Flatten())\n",
    "# # model.add(Dense(12, activation='relu'))\n",
    "# # model.add(Dense(32, activation='relu'))\n",
    "# # model.add(Dense(32, activation='relu'))\n",
    "# # model.add(Dense(16, activation='relu'))\n",
    "# # model.add(Dense(2, activation='sigmoid'))\n",
    "# # model.build(input_shape)\n",
    "# model.summary()\n",
    "# model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'], run_eagerly=True)\n",
    "\n",
    "# model.fit(\n",
    "#     train_gen,\n",
    "#     validation_data=validation_gen,\n",
    "#     epochs=25,\n",
    "#     steps_per_epoch=train_gen.samples // BATCH_SIZE,\n",
    "#     validation_steps=validation_gen.samples // BATCH_SIZE\n",
    "# )\n",
    "\n",
    "# _, accuracy = model.evaluate(train_gen, validation_gen)\n",
    "# print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "\n",
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs = range(len(acc))\n",
    "\n",
    "# plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "# plt.title('Training and validation accuracy')\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "# plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 62 images belonging to 8 classes.\n",
      "Found 10 images belonging to 8 classes.\n",
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_31 (InputLayer)       [(None, 220, 380, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 220, 380, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 220, 380, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 110, 190, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 110, 190, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 110, 190, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 55, 95, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 55, 95, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 55, 95, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 55, 95, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 27, 47, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 27, 47, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 27, 47, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 27, 47, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 13, 23, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 13, 23, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 13, 23, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 13, 23, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 6, 11, 512)        0         \n",
      "                                                                 \n",
      " flatten_33 (Flatten)        (None, 33792)             0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 128)               4325504   \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,041,224\n",
      "Trainable params: 4,326,536\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 8.6199 - categorical_accuracy: 0.0435\n",
      "Epoch 2/62\n",
      "3/3 [==============================] - 8s 3s/step - loss: 4.5520 - categorical_accuracy: 0.1304\n",
      "Epoch 3/62\n",
      "3/3 [==============================] - 9s 3s/step - loss: 2.4292 - categorical_accuracy: 0.2174\n",
      "Epoch 4/62\n",
      "3/3 [==============================] - 9s 3s/step - loss: 2.1940 - categorical_accuracy: 0.1957\n",
      "Epoch 5/62\n",
      "3/3 [==============================] - 9s 3s/step - loss: 2.0491 - categorical_accuracy: 0.1957\n",
      "Epoch 6/62\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.9259 - categorical_accuracy: 0.2391\n",
      "Epoch 7/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.9769 - categorical_accuracy: 0.1304\n",
      "Epoch 8/62\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.8604 - categorical_accuracy: 0.2826\n",
      "Epoch 9/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.8707 - categorical_accuracy: 0.2708\n",
      "Epoch 10/62\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.7999 - categorical_accuracy: 0.3261\n",
      "Epoch 11/62\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.6890 - categorical_accuracy: 0.3696\n",
      "Epoch 12/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.6917 - categorical_accuracy: 0.3696\n",
      "Epoch 13/62\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.7004 - categorical_accuracy: 0.4375\n",
      "Epoch 14/62\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.5981 - categorical_accuracy: 0.4783\n",
      "Epoch 15/62\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.6652 - categorical_accuracy: 0.3913\n",
      "Epoch 16/62\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.6001 - categorical_accuracy: 0.5000\n",
      "Epoch 17/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.5587 - categorical_accuracy: 0.6304\n",
      "Epoch 18/62\n",
      "3/3 [==============================] - 11s 3s/step - loss: 1.5534 - categorical_accuracy: 0.5208\n",
      "Epoch 19/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.4884 - categorical_accuracy: 0.5417\n",
      "Epoch 20/62\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.4941 - categorical_accuracy: 0.6739\n",
      "Epoch 21/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.4108 - categorical_accuracy: 0.5417\n",
      "Epoch 22/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.5709 - categorical_accuracy: 0.4130\n",
      "Epoch 23/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.3956 - categorical_accuracy: 0.6304\n",
      "Epoch 24/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.3610 - categorical_accuracy: 0.5870\n",
      "Epoch 25/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.4005 - categorical_accuracy: 0.6042\n",
      "Epoch 26/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.3073 - categorical_accuracy: 0.5217\n",
      "Epoch 27/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.3259 - categorical_accuracy: 0.4348\n",
      "Epoch 28/62\n",
      "3/3 [==============================] - 11s 3s/step - loss: 1.3127 - categorical_accuracy: 0.5625\n",
      "Epoch 29/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.3282 - categorical_accuracy: 0.5435\n",
      "Epoch 30/62\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.1640 - categorical_accuracy: 0.7609\n",
      "Epoch 31/62\n",
      "3/3 [==============================] - 11s 3s/step - loss: 1.3603 - categorical_accuracy: 0.5833\n",
      "Epoch 32/62\n",
      "3/3 [==============================] - 11s 3s/step - loss: 1.2186 - categorical_accuracy: 0.6250\n",
      "Epoch 33/62\n",
      "3/3 [==============================] - 12s 4s/step - loss: 1.1277 - categorical_accuracy: 0.6667\n",
      "Epoch 34/62\n",
      "3/3 [==============================] - 11s 3s/step - loss: 1.0855 - categorical_accuracy: 0.8043\n",
      "Epoch 35/62\n",
      "3/3 [==============================] - 11s 3s/step - loss: 1.1340 - categorical_accuracy: 0.7083\n",
      "Epoch 36/62\n",
      "3/3 [==============================] - 11s 3s/step - loss: 1.1443 - categorical_accuracy: 0.6667\n",
      "Epoch 37/62\n",
      "3/3 [==============================] - 11s 3s/step - loss: 1.1089 - categorical_accuracy: 0.6739\n",
      "Epoch 38/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.0984 - categorical_accuracy: 0.6957\n",
      "Epoch 39/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.0647 - categorical_accuracy: 0.7826\n",
      "Epoch 40/62\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.9908 - categorical_accuracy: 0.6739\n",
      "Epoch 41/62\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.9817 - categorical_accuracy: 0.7500\n",
      "Epoch 42/62\n",
      "3/3 [==============================] - 11s 3s/step - loss: 1.0133 - categorical_accuracy: 0.8125\n",
      "Epoch 43/62\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.0734 - categorical_accuracy: 0.6957\n",
      "Epoch 44/62\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.9203 - categorical_accuracy: 0.7826\n",
      "Epoch 45/62\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.9367 - categorical_accuracy: 0.6957\n",
      "Epoch 46/62\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.7148 - categorical_accuracy: 0.9348\n",
      "Epoch 47/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.9568 - categorical_accuracy: 0.7391\n",
      "Epoch 48/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.8912 - categorical_accuracy: 0.7826\n",
      "Epoch 49/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.9048 - categorical_accuracy: 0.7391\n",
      "Epoch 50/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.8919 - categorical_accuracy: 0.8478\n",
      "Epoch 51/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.8331 - categorical_accuracy: 0.8043\n",
      "Epoch 52/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.9412 - categorical_accuracy: 0.7391\n",
      "Epoch 53/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.7498 - categorical_accuracy: 0.8261\n",
      "Epoch 54/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.8463 - categorical_accuracy: 0.7826\n",
      "Epoch 55/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.8216 - categorical_accuracy: 0.7609\n",
      "Epoch 56/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.7926 - categorical_accuracy: 0.7708\n",
      "Epoch 57/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.8509 - categorical_accuracy: 0.7917\n",
      "Epoch 58/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.7218 - categorical_accuracy: 0.8043\n",
      "Epoch 59/62\n",
      "3/3 [==============================] - 11s 3s/step - loss: 0.6162 - categorical_accuracy: 0.9130\n",
      "Epoch 60/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.6762 - categorical_accuracy: 0.9130\n",
      "Epoch 61/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.6527 - categorical_accuracy: 0.9348\n",
      "Epoch 62/62\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.7092 - categorical_accuracy: 0.8750\n",
      "{'loss': [8.619893074035645, 4.5520405769348145, 2.4292261600494385, 2.194007635116577, 2.049135208129883, 1.9258756637573242, 1.9768773317337036, 1.8603870868682861, 1.8706945180892944, 1.7998743057250977, 1.6890162229537964, 1.6917388439178467, 1.7003618478775024, 1.5981193780899048, 1.6651555299758911, 1.6000632047653198, 1.5586594343185425, 1.5533894300460815, 1.4883817434310913, 1.4940835237503052, 1.410835862159729, 1.5709320306777954, 1.3956232070922852, 1.3609991073608398, 1.4004864692687988, 1.3073328733444214, 1.3258837461471558, 1.312675952911377, 1.3282499313354492, 1.1640405654907227, 1.3603280782699585, 1.218599796295166, 1.1277133226394653, 1.0854923725128174, 1.1339904069900513, 1.1442960500717163, 1.10892915725708, 1.0983620882034302, 1.0647244453430176, 0.9907951354980469, 0.9817419648170471, 1.0132848024368286, 1.073440670967102, 0.920348048210144, 0.9367355108261108, 0.7148350477218628, 0.9567533731460571, 0.8911736607551575, 0.904836893081665, 0.8918952941894531, 0.8331468105316162, 0.9411690831184387, 0.7498298287391663, 0.8463030457496643, 0.8216198682785034, 0.792550265789032, 0.8509147763252258, 0.7218252420425415, 0.6161969900131226, 0.6762212514877319, 0.6526694297790527, 0.709161102771759], 'categorical_accuracy': [0.043478261679410934, 0.1304347813129425, 0.21739129722118378, 0.19565217196941376, 0.19565217196941376, 0.239130437374115, 0.1304347813129425, 0.28260868787765503, 0.2708333432674408, 0.32608696818351746, 0.3695652186870575, 0.3695652186870575, 0.4375, 0.47826087474823, 0.3913043439388275, 0.5, 0.6304348111152649, 0.5208333134651184, 0.5416666865348816, 0.6739130616188049, 0.5416666865348816, 0.41304346919059753, 0.6304348111152649, 0.5869565010070801, 0.6041666865348816, 0.52173912525177, 0.43478259444236755, 0.5625, 0.54347825050354, 0.760869562625885, 0.5833333134651184, 0.625, 0.6666666865348816, 0.804347813129425, 0.7083333134651184, 0.6666666865348816, 0.6739130616188049, 0.695652186870575, 0.782608687877655, 0.6739130616188049, 0.75, 0.8125, 0.695652186870575, 0.782608687877655, 0.695652186870575, 0.9347826242446899, 0.739130437374115, 0.782608687877655, 0.739130437374115, 0.8478260636329651, 0.804347813129425, 0.739130437374115, 0.8260869383811951, 0.782608687877655, 0.760869562625885, 0.7708333134651184, 0.7916666865348816, 0.804347813129425, 0.9130434989929199, 0.9130434989929199, 0.9347826242446899, 0.875]}\n"
     ]
    }
   ],
   "source": [
    "from numpy import expand_dims\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.datasets import cifar10\n",
    "from keras.optimizers import sgd_experimental\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import *\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "TEST_TUBE_PATH = \"./Test Tubes\"\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "input_shape_w, input_shape_h = 220, 380\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    # vertical_flip=True,\n",
    "    brightness_range=(0.2, 0.5),\n",
    "    # rotation_range=90,\n",
    "    validation_split=0.2,\n",
    "    # samplewise_std_normalization=True,\n",
    ")\n",
    "\n",
    "valgen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "train_generator=datagen.flow_from_directory(\n",
    "    TEST_TUBE_PATH,\n",
    "    target_size=(input_shape_w, input_shape_h),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes = ['BD-Vacutainer','EDTA(K2)','Monovette','PLAIN','SGS', 'Vacuette', 'Vacutest', 'Venosafe'],\n",
    "    subset=\"training\",\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = valgen.flow_from_directory(\n",
    "    TEST_TUBE_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(input_shape_w, input_shape_h),\n",
    "    subset=\"validation\",\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "\n",
    "model = VGG16(include_top=False, input_shape=(input_shape_w, input_shape_h, 3))\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(Flatten()(model.layers[-1].output))\n",
    "class2 = Dense(64, activation='relu', kernel_initializer='he_uniform')(class1)\n",
    "output = Dense(8, activation='softmax')(class2)\n",
    "model = Model(inputs=model.inputs, outputs=output)\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    epochs=train_generator.samples,\n",
    "    verbose=1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps = validation_generator.samples // BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(history.history)\n",
    "\n",
    "_, accuracy = model.evaluate(train_generator, validation_generator)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "# acc = history.history['categorical_accuracy']\n",
    "# val_acc = history.history['val_categorical_accuracy']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4f3e34985d48c0de54ade8e82ec9ac0e446a4a3f4e3aac138c19eb44b9d57a9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
